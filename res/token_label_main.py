from torch import true_divide
from labling_tool import *
import sys
sys.path.append('/home/sayi/workspace/pii/I_want_PII_NER/res')
from token_base import dont_care, should_check, others
from random_base import vast_cities, cities, do, gun, gu

root_path = '/home/sayi/workspace/pii/'
project_path = root_path + 'I_want_PII_NER/'

insurance_lable = "res/insurance_labled"
intergrated = "res/intergrated_sangheon.tsv"
test = "res/test.tsv"
train = "res/train.tsv"
all_intergrated = "C:/Exception/new_one.tsv"
result = "C:/Exception/I_want_PII_NER/res/result"
qa_lable = "res/QAlable"
out_file = "res/filling.kt"
token_label = "res/token_label_origin.tsv"
token_label = "res/token_label.tsv"
file_path = project_path + "res/duplabeld.tsv"

def is_city(token):
    city_base = vast_cities + cities + do + gun + gu
    for city_part in city_base:
        if token in city_part:
            return True
    return False
other_city = set()

for other in others:
    stripped_other = other
    if "##" in other:
        stripped_other = other.strip('##')
    if is_city(stripped_other):
        other_city.add(other)
        
with open(project_path + token_label, "r", encoding="utf-8") as file, open(project_path + out_file, "w", encoding="utf-8") as edited_file:
    total_cnt = 0
    edit_cnt = 0
    changed = ''
    [   
    #   done
    '##ê°', '##ê°€', '##ê°•',  '##ê°€ìš”', '##ê²Œ', '##ìƒ', '##ê³ ', '##ê³„', '##ê´‘', '##êµ', '##ë‚˜', '##ë„¤', '##ë‹¤', '##ë‹ˆ', '##ë„', '##ë“œ', '##ë¼',  '##ë¼ëŠ”', '##ëŸ¬', '##ë Œ', '##ë¡œ',  '##ë¦¬', '##ëª¨',
    '##ë§Œ', '##ë³´', '##ë²ˆ', '##ì„œ', '##ì‚¬', '##ì„¼í„°',  '##ì†Œ', '##ì‹œ', '##ì•ˆ',  '##ì•„', '##ì•„ì´',  '##ì‹ ', '##ì–‘','##ì–´',  '##ì–¸', '##ì—¬', '##ì—', '##ì˜ˆ', '##ì˜', '##ì›',
    # check
    #  '##ì´', '##ìŒ', '##ì ‘',  '##ì¥', '##ì¸', '##ì¢…', '##ì£¼', '##ì§€', '##ì°½', 
    # '##íŠ¸', '##í•œ', '##í¬',  '##í•˜', 'ë¡œ', 'ë§Œ','ë¬¸ê²½', 'ë¯¸', 'ë¶„ë‹¹', 'ì‚¬', 'ì„±ì‚°',  'ì‹ ', 'ì—°ì œ', 'ì˜¤ì‚°',  'ì€', 'ì´', 'ì „ë¶', 'ì¤‘ë‘',
    # ì‹œ, ë„, êµ¬, êµ°
    # '##êµ¬', '##êµ°',  '##ë©´','ëŒ€êµ¬', 'ê´‘ì£¼', 'ë‚¨ì›', 'ë‚´', 'ë„ë´‰',  'ë•', 
     # age
]
    check_chars =[
     #   done
    # '##ê°', '##ê°€', '##ê°•',  
    # '##ê°€ìš”', '##ê²Œ', '##ìƒ', '##ê³ ', '##ê³„', '##ê´‘', '##êµ', '##ë‚˜', '##ë„¤', '##ë‹¤', '##ë‹ˆ', '##ë„', '##ë“œ', '##ë¼',  '##ë¼ëŠ”', '##ëŸ¬', '##ë Œ', '##ë¡œ',  '##ë¦¬', '##ëª¨',
    # '##ë§Œ', '##ë³´', '##ë²ˆ', '##ì„œ', '##ì‚¬', '##ì„¼í„°',  '##ì†Œ', '##ì‹œ', '##ì•ˆ',  '##ì•„', '##ì•„ì´',  '##ì‹ ', '##ì–‘','##ì–´',  '##ì–¸', '##ì—¬', '##ì—', '##ì˜ˆ', '##ì˜', '##ì›',
    
    # check
    #  '##ì´', '##ìŒ', '##ì ‘',  '##ì¥', '##ì¸', '##ì¢…', '##ì£¼', '##ì§€', '##ì°½', 
    # '##íŠ¸', '##í•œ', '##í¬',  '##í•˜', 'ë¡œ', 'ë§Œ','ë¬¸ê²½', 'ë¯¸', 'ë¶„ë‹¹', 'ì‚¬', 'ì„±ì‚°',  'ì‹ ', 'ì—°ì œ', 'ì˜¤ì‚°',  'ì€', 'ì´', 'ì „ë¶', 'ì¤‘ë‘',
    # ì‹œ, ë„, êµ¬, êµ°
    # '##êµ¬', '##êµ°',  '##ë©´','ëŒ€êµ¬', 'ê´‘ì£¼', 'ë‚¨ì›', 'ë‚´', 'ë„ë´‰',  'ë•', 
     # age
     ]
    print_set = set()
    found_label = ''
    found_line_idx = set()
    check_label =['s', 'd', 'd']
    for line_idx, line in enumerate(file):
        if total_cnt > 1000:
            break
        tokens, labels = splitTokenAndLable(line)
        tmp = []
        

        # if line_idx in [10, 38, 127, 476, 480, 493]:
        #     continue
        for i, token in enumerate(tokens):
            # and not ( 'NAME'  in labels[i] or 'BRAND'  in labels[i] or 'AGE'  in labels[i] )\
            # if token in others  and 'AD_ADDRESS-I' in labels and 'AD_CITY-B' not in labels and not ( 's'  in labels[i] or 's'  in labels[i] or 's'  in labels[i]):
            if token in other_city and 'AD_CITY-B' not in labels:
                found_line_idx.add(line_idx)
                # if labels[i] in ['ID_PHONE-I', 'ID_INUM-I']:
                total_cnt += 1
                print_set.add(token)
                if line_idx in [  ]:
                # if check_label[0] in labels[i] :
                # if 'í™•' in tokens[i + 1]:
                    edit_cnt+=1
                    labels[i] = 'AD_CITY-B'
                token = 'ğŸ¤´' + token + 'ğŸ¤´'
                found_label = labels[i]
            tmp.append(token + ' ' + labels[i])
            # tmp.append(token)
        tmp = ' '.join(tmp)
        if 'ğŸ¤´' in tmp:
            tmp += f'ğŸ•µï¸â€â™€ï¸\n{line_idx}, {found_label} ğŸ•µï¸â€â™€ï¸\n'
            print(tmp)
        line = ' '.join(tokens) + '\t' + ' '.join(labels) + '\n'
        edited_file.write(line)
    print(check_chars, check_label)
    print(f'found cnt: {edit_cnt} / {total_cnt} line_cnt: {len(found_line_idx)} idx: {found_line_idx}')
    print(other_city)